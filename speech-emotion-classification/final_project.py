# -*- coding: utf-8 -*-
"""Final Project

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Qku0iqWaVTCgfHISllRM2hiFN4HVn5OZ

Import statements
"""

from sklearn.model_selection import train_test_split
from sklearn.svm import SVC
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import GridSearchCV
from sklearn.metrics import classification_report, confusion_matrix
from sklearn.metrics import accuracy_score
import os
import librosa
import librosa.display
import IPython.display as ipd
import numpy as np
import csv
from google.colab import drive
from sklearn.model_selection import KFold
from sklearn.preprocessing import LabelEncoder

drive.mount('/content/drive')

data_path = '/content/drive/Shareddrives/ELEC_378_Final/ELEC378_Final_Project/final_project/data'
test_path = '/content/drive/Shareddrives/ELEC_378_Final/ELEC378_Final_Project/final_project/test'

"""GMM"""

from sklearn.mixture import GaussianMixture

"""Feature Extraction"""

# Set the number of Mel-Frequency Cepstral Coefficients (MFCCs) to extract.
num_mfcc = 20

# Initialize empty arrays to hold the feature matrix from audio and corresponding labels.
X_train = []
y_train = []

# Iterate through all of the .wav files in the training directory.
for file in sorted(os.listdir(data_path)):
    if file.endswith(".wav"):
        # Load the audio file using librosa and our files in Google Drive.
        audio_data, sample_rate = librosa.load(os.path.join(data_path, file))

        # Determine the MFCC features from the audio data provided above.
        mfccs = librosa.feature.mfcc(y=audio_data, sr=sample_rate, n_mfcc=num_mfcc)

        # Grab the mean and standard deviation of our features.
        mfccs_avg = np.mean(mfccs, axis=1)
        mfccs_std = np.std(mfccs, axis=1)

        # Add the MFCC features to the data matrix
        X_train.append(np.concatenate((mfccs_avg, mfccs_std)))

        # Determine the emotion label of the audio file based on its filename.
        label = ""
        idx = 0
        while not (file[idx].isdigit()):
            label += file[idx]
            idx += 1
        y_train.append(label)

"""Split Data into Training and Validation"""

# Convert our data into np.arrays
X_train = np.array(X_train)
y_train = np.array(y_train)

# Use stratified sampling to split the data into a smaller training set and a validation set
X_train_new, X_val, y_train_new, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42, stratify=y_train)

# Load pre-processed MFCC features and emotion labels
#X = np.load('mfcc_features.npy')
#y = np.load('emotion_labels.npy')

# Split data into training and testing sets
#X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Train a GMM model for each emotion class
n_components = 60
covariance_type = 'full'
emotion_classes = ['angry', 'disgust', 'fearful', 'happy', 'neutral', 'sad', 'surprise', 'calm']
models = []
#print(y_train == 'surprise')
for emotion in emotion_classes:
    #print(emotion)
    # Get training data for current emotion class
    X_emotion = X_train_new[y_train_new == emotion]
    # Train a GMM model for current emotion class
    model = GaussianMixture(n_components=n_components, reg_covar=1e-06, covariance_type=covariance_type)
    if X_emotion.shape[0] != 0:
         model.fit(X_emotion)
         models.append(model)

# Classify testing data using the trained GMM models
y_pred = []
for mfcc in X_val:
    likelihoods = []
    for model in models:
        # Calculate likelihood of mfcc belonging to current emotion class
        likelihood = np.exp(model.score(mfcc.reshape(1, -1)))
        likelihoods.append(likelihood)
    # Assign emotion class with highest likelihood as predicted emotion
    pred_emotion = emotion_classes[np.argmax(likelihoods)]
    y_pred.append(pred_emotion)

# Evaluate performance of the GMM classifier
accuracy = accuracy_score(y_val, y_pred)
print('Accuracy:', accuracy)

# Print the classification report and confusion matrix for the validation set
print(classification_report(y_val, y_pred))
print(confusion_matrix(y_val, y_pred))

"""Test: Predictions"""

scaler = StandardScaler()
X_test = []
file_names = []
for file in sorted(os.listdir(test_path)):
    if file.endswith(".wav"):

        file_names.append(file.split(".")[0])

        # Load the audio file using librosa and our files in Google Drive.
        audio_data, sample_rate = librosa.load(os.path.join(test_path, file))

        # Determine the MFCC features from the audio data provided above.
        mfccs = librosa.feature.mfcc(y=audio_data, sr=sample_rate, n_mfcc=num_mfcc)

        # Grab the mean and standard deviation of our features.
        mfccs_avg = np.mean(mfccs, axis=1)
        mfccs_std = np.std(mfccs, axis=1)

        # Add the MFCC features to the data matrix
        X_test.append(np.concatenate((mfccs_avg.reshape(-1), mfccs_std.reshape(-1))))

X_test = np.array(X_test)

# Predict the labels of the test data using the trained SVM classifier
#y_pred_test = svm_classifier.predict(X_test)
# Classify testing data using the trained GMM models
y_pred_test = []
for mfcc in X_test:
    likelihoods = []
    for model in models:
        # Calculate likelihood of mfcc belonging to current emotion class
        likelihood = np.exp(model.score(mfcc.reshape(1, -1)))
        likelihoods.append(likelihood)
    # Assign emotion class with highest likelihood as predicted emotion
    pred_emotion = emotion_classes[np.argmax(likelihoods)]
    y_pred_test.append(pred_emotion)

# Convert the file names and predicted labels to a two-dimensional numpy array
predictions = np.column_stack((file_names, y_pred_test))

# Sort the predictions array by the first column (the sorted file names)
predictions = predictions[np.lexsort((predictions[:, 0],))]

# Save the predictions to a CSV file
np.savetxt("predictions.csv", predictions, fmt='%s', delimiter=",", encoding='utf-8')
with open("predictions.csv", "r+") as f:
    content = f.read()
    f.seek(0, 0)
    f.write("filename,Label\n" + content)

"""Simple SVM Model

Plots
"""

!pip install matplotlib

import matplotlib.pyplot as plt
import librosa.display

# plot the MFCCs heatmap
def plot_mfccs(mfccs):
    plt.figure(figsize=(10, 4))
    librosa.display.specshow(mfccs, x_axis='time')
    plt.colorbar()
    plt.title('MFCC')
    plt.tight_layout()
    plt.show()

#plot a grid of MFCCs.
def plot_mfccs_subplot(mfccs, ax):
    img = librosa.display.specshow(mfccs, x_axis='time', ax=ax)
    return img

"""Feature Extraction"""

# Set the number of Mel-Frequency Cepstral Coefficients (MFCCs) to extract.
num_mfcc = 20

# Initialize empty arrays to hold the feature matrix from audio and corresponding labels.
X_train = []
y_train = []

# Set the number of rows and columns for the subplot grid
num_rows = 4
num_cols = 4

# Keep track of the current subplot index
subplot_idx = 1

# Create a new figure for the grid of subplots
fig, axes = plt.subplots(num_rows, num_cols, figsize=(15, 10))
fig.tight_layout(pad=2.0)

# Iterate through all of the .wav files in the training directory.
for file in sorted(os.listdir(data_path)):
    if file.endswith(".wav"):
        # Load the audio file using librosa and our files in Google Drive.
        audio_data, sample_rate = librosa.load(os.path.join(data_path, file))

        # Determine the MFCC features from the audio data provided above.
        mfccs = librosa.feature.mfcc(y=audio_data, sr=sample_rate, n_mfcc=num_mfcc)
        #print(mfccs)

        # Plot the MFCCs
        # plot_mfccs(mfccs)
        # Plot the MFCCs in the corresponding subplot
        row = (subplot_idx - 1) // num_cols
        col = (subplot_idx - 1) % num_cols
        img = plot_mfccs_subplot(mfccs, axes[row, col])
        axes[row, col].set_title(file)

        # Increment the subplot index
        subplot_idx += 1

        if subplot_idx > num_rows * num_cols:
            break

        # Grab the mean and standard deviation of our features.
        mfccs_avg = np.mean(mfccs, axis=1)
        mfccs_std = np.std(mfccs, axis=1)

        # Add the MFCC features to the data matrix
        X_train.append(np.concatenate((mfccs_avg, mfccs_std)))

        # Determine the emotion label of the audio file based on its filename.
        label = ""
        idx = 0
        while not (file[idx].isdigit()):
            label += file[idx]
            idx += 1
        y_train.append(label)

# Add a colorbar to the figure
cbar = fig.colorbar(img, ax=axes.ravel().tolist())
cbar.set_label('Amplitude (dB)')

# Show the figure
plt.show()

"""Split data into training and validation data


"""

# Convert our data into np.arrays for SVM.
X_train = np.array(X_train)
y_train = np.array(y_train)

# Use stratified sampling to split the data into a smaller training set and a validation set
X_train_new, X_val, y_train_new, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42, stratify=y_train)

# Initialize the SVM classifier
svm_classifier = SVC(kernel='linear', C=10, gamma=0.1)

# Train the SVM classifier on the smaller training set
svm_classifier.fit(X_train_new, y_train_new)

# Predict the labels of the validation set using the trained SVM classifier
y_pred_val = svm_classifier.predict(X_val)

# Print the classification report and confusion matrix for the validation set
print(classification_report(y_val, y_pred_val))
print(confusion_matrix(y_val, y_pred_val))

"""Improved model SVM"""

!pip install tune-sklearn

# from sklearn.metrics import classification_report, confusion_matrix
# from tune_sklearn import TuneSearchCV
# from ray.tune.schedulers import ASHAScheduler

# # Convert our data into np.arrays for SVM.
# X_train = np.array(X_train)
# y_train = np.array(y_train)

# # Use stratified sampling to split the data into a smaller training set and a validation set
# X_train_new, X_val, y_train_new, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42, stratify=y_train)

# # Define the hyperparameter search space
# params = {
#     "C": [0.1, 1, 10],
#     "gamma": [0.1, 1, 10],
#     "kernel": ["linear", "rbf"]
# }

# # Initialize the SVM classifier
# svm_classifier = SVC()

# # Define the Tune hyperparameter search
# tune_search = TuneSearchCV(svm_classifier, params, n_jobs=-1, search_optimization="random", cv=5, scoring="accuracy")

# # Set up the ASHA scheduler
# scheduler = ASHAScheduler(
#     metric="accuracy",
#     mode="max",
#     max_t=10,
#     grace_period=1,
#     reduction_factor=2
# )

# # Perform the hyperparameter search with Tune
# tune_search.fit(X_train_new, y_train_new, callbacks=[scheduler])

# # Print the best hyperparameters and score found by Tune
# print("Best parameters:", tune_search.best_params_)
# print("Best score:", tune_search.best_score_)

"""Optimize run time"""

pip install scikit-optimize

from skopt import BayesSearchCV
from skopt.space import Real, Categorical, Integer
from sklearn.preprocessing import StandardScaler
from sklearn.svm import SVC

# Set the number of Mel-Frequency Cepstral Coefficients (MFCCs) to extract.
num_mfcc = 20

# Initialize empty arrays to hold the feature matrix from audio and corresponding labels.
X_train = []
y_train = []

# Iterate through all of the .wav files in the training directory.
for file in sorted(os.listdir(data_path)):
    if file.endswith(".wav"):
        # Load the audio file using librosa and our files in Google Drive.
        audio_data, sample_rate = librosa.load(os.path.join(data_path, file))

        # Determine the MFCC features from the audio data provided above.
        mfccs = librosa.feature.mfcc(y=audio_data, sr=sample_rate, n_mfcc=num_mfcc)


        # Grab the mean and standard deviation of our features.
        mfccs_avg = np.mean(mfccs, axis=1)
        mfccs_std = np.std(mfccs, axis=1)

        # Add the MFCC features to the data matrix
        X_train.append(np.concatenate((mfccs_avg, mfccs_std)))

        # Determine the emotion label of the audio file based on its filename.
        label = ""
        idx = 0
        while not (file[idx].isdigit()):
            label += file[idx]
            idx += 1
        y_train.append(label)




# Define the hyperparameter search space
params = {
    "C": Real(1e-6, 1e+6, prior="log-uniform"),
    "gamma": Real(1e-6, 1e+1, prior="log-uniform"),
    "kernel": Categorical(["poly", "sigmoid"]),
    "degree": Integer(1, 5),
    "coef0": Real(-1, 1)
}

# Initialize the SVM classifier
svm_classifier = SVC()

# Define the Skopt hyperparameter search
skopt_search = BayesSearchCV(
    svm_classifier,
    params,
    n_iter=20,
    cv=5,
    n_jobs=-1,
    scoring="accuracy",
    random_state=42
)

# Apply feature scaling to the dataset
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
#X_test_scaled = scaler.transform(X_test)

# Perform the hyperparameter search with Skopt
#skopt_search.fit(X_train, y_train)
skopt_search.fit(X_train_scaled, y_train)

# Print the best hyperparameters and score found by Skopt
print("Best parameters:", skopt_search.best_params_)
print("Best score:", skopt_search.best_score_)

"""Data processing (Model: SVM)"""

# Initialize the SVM classifier with the best hyperparameters found by Skopt
svm_classifier = SVC(C=skopt_search.best_params_['C'], gamma=skopt_search.best_params_['gamma'], kernel=skopt_search.best_params_['kernel'])

# Use stratified sampling to split the data into a smaller training set and a validation set
X_train_new, X_val, y_train_new, y_val = train_test_split(
     X_train, y_train, test_size=0.2, random_state=42, stratify=y_train)

svm_classifier.fit(X_train_new, y_train_new)


# Predict the labels of the validation set using the trained SVM classifier
y_pred_val = svm_classifier.predict(X_val)

# Predict the labels of the validation set using the trained SVM classifier
y_pred_val = svm_classifier.predict(X_val)

# Print the classification report and confusion matrix for the validation set
print(classification_report(y_val, y_pred_val))
print(confusion_matrix(y_val, y_pred_val))

# Predict the labels of the test data using the trained SVM classifier
X_test = []
file_names = []
for file in sorted(os.listdir(test_path)):
    if file.endswith(".wav"):

        file_names.append(file.split(".")[0])

        # Load the audio file using librosa and our files in Google Drive.
        audio_data, sample_rate = librosa.load(os.path.join(test_path, file))

        # Determine the MFCC features from the audio data provided above.
        mfccs = librosa.feature.mfcc(y=audio_data, sr=sample_rate, n_mfcc=num_mfcc)

        # Grab the mean and standard deviation of our features.
        mfccs_avg = np.mean(mfccs, axis=1)
        mfccs_std = np.std(mfccs, axis=1)

        # Add the MFCC features to the data matrix
        X_test.append(np.concatenate((mfccs_avg.reshape(-1), mfccs_std.reshape(-1))))

X_test = np.array(X_test)

# Predict the labels of the test data using the trained SVM classifier
y_pred_test = svm_classifier.predict(X_test)

# Convert the file names and predicted labels to a two-dimensional numpy array
predictions = np.column_stack((file_names, y_pred_test))

# Sort the predictions array by the first column (the sorted file names)
predictions = predictions[np.lexsort((predictions[:, 0],))]

# Save the predictions to a CSV file
np.savetxt("predictions.csv", predictions, fmt='%s', delimiter=",", encoding='utf-8')
with open("predictions.csv", "r+") as f:
    content = f.read()
    f.seek(0, 0)
    f.write("filename,Label\n" + content)

# # Scale the feature matrix to have zero mean and unit variance
# scaler = StandardScaler()
# X_train = scaler.fit_transform(X_train)

# # Initialize the SVM classifier and perform hyperparameter tuning using GridSearchCV
# svm_classifier = SVC()
# param_grid = {'C': [0.1, 1, 10], 'gamma': [0.1, 1, 10], 'kernel': ['linear', 'rbf', 'sigmoid']}
# grid = GridSearchCV(svm_classifier, param_grid, cv=5, n_jobs=-1)
# grid.fit(X_train, y_train.ravel())

# # Print the best hyperparameters found by GridSearchCV
# print("Best parameters:", grid.best_params_)
# print("Best score:", grid.best_score_)

# # Train the SVM classifier on the training data using the best hyperparameters
# svm_classifier = SVC(**grid.best_params_)
# svm_classifier.fit(X_train, y_train.ravel())

# # Predict the labels of the test data using the trained SVM classifier
# file_names = []
# X_test = []
# # y_test = []

# # Iterate through all of the .wav files in the testing directory.
# for file in sorted(os.listdir(test_path)):
#     if file.endswith(".wav"):

#         file_names.append(file.split(".")[0])

#         # Load the audio file using librosa and our files in Google Drive.
#         audio_data, sample_rate = librosa.load(os.path.join(test_path, file))

#         # Determine the MFCC features from the audio data provided above.
#         mfccs = librosa.feature.mfcc(y=audio_data, sr=sample_rate, n_mfcc=num_mfcc)

#         # Grab the mean and standard deviation of our features.
#         mfccs_avg = np.mean
#         mfccs_std = np.std(mfccs, axis=1)

#         # Add the MFCC features to the data matrix
#         mfccs_avg_arr = np.mean(mfccs, axis=1)
#         mfccs_std_arr = np.std(mfccs, axis=1)

#         X_test.append(np.concatenate((mfccs_avg_arr.reshape(-1), mfccs_std_arr.reshape(-1))))

# X_test = np.array(X_test)

# # Scale the test data using the same scaler used for the training data
# X_test = scaler.transform(X_test)

# # Predict the labels of the test data using the trained SVM classifier
# y_pred = svm_classifier.predict(X_test)

# # Convert the file names and predicted labels to a two-dimensional numpy array
# predictions = np.column_stack((file_names, y_pred))

# # Sort the predictions array by the first column (the sorted file names)
# predictions = predictions[np.lexsort((predictions[:, 0],))]

# # Save the predictions to a CSV file
# np.savetxt("predictions.csv", predictions, fmt='%s', delimiter=",", encoding='utf-8')
# with open("predictions.csv", "r+") as f:
#     content = f.read()
#     f.seek(0, 0)
#     f.write("filename,Label\n" + content)

# # Evaluate the performance of the SVM classifier on the test data using classification report and confusion matrix
# # print(classification_report(y_test, y_pred))
# # print(confusion_matrix(y_test, y_pred))

"""CNNs implimentation."""

pip install tensorflow

import os
import numpy as np
import librosa
import tensorflow as tf
from sklearn.preprocessing import LabelEncoder
from sklearn.model_selection import train_test_split
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dense, Flatten, Dropout
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping

"""Features Extraction"""

# Set the number of Mel-Spectrogram bands to extract.
n_mels = 128

# Initialize empty arrays to hold the feature matrix from audio and corresponding labels.
X_train = []
y_train = []

# Determine the maximum time length
max_time_length = 0
for file in sorted(os.listdir(data_path)):
    if file.endswith(".wav"):
        audio_data, sample_rate = librosa.load(os.path.join(data_path, file))
        spectrogram = librosa.feature.melspectrogram(y=audio_data, sr=sample_rate, n_mels=n_mels)
        max_time_length = max(max_time_length, spectrogram.shape[1])

# Iterate through all of the .wav files in the training directory.
for file in sorted(os.listdir(data_path)):
    if file.endswith(".wav"):
        # Load the audio file using librosa and our files in Google Drive.
        audio_data, sample_rate = librosa.load(os.path.join(data_path, file))

        # Determine the Mel-Spectrogram features from the audio data provided above.
        spectrogram = librosa.feature.melspectrogram(y=audio_data, sr=sample_rate, n_mels=n_mels)

        # Pad the spectrogram to have the same time length
        pad_width = max_time_length - spectrogram.shape[1]
        spectrogram_padded = np.pad(spectrogram, pad_width=((0, 0), (0, pad_width)), mode='constant')

        # Add the Mel-Spectrogram features to the data matrix
        X_train.append(spectrogram_padded)

        # Determine the emotion label of the audio file based on its filename.
        label = ""
        idx = 0
        while not (file[idx].isdigit()):
            label += file[idx]
            idx += 1
        y_train.append(label)

# Convert our data into np.arrays and expand the dimensions
X_train = np.array(X_train)[:, :, :, np.newaxis]
y_train = np.array(y_train)

# Encode the labels
encoder = LabelEncoder()
y_train_encoded = encoder.fit_transform(y_train)

# Split the data into training and validation sets
X_train, X_val, y_train, y_val = train_test_split(X_train, y_train_encoded, test_size=0.2, random_state=42, stratify=y_train_encoded)

# Create the CNN model
model = Sequential([
    Conv2D(32, (3, 3), activation='relu', input_shape=(n_mels, max_time_length, 1)),
    MaxPooling2D((2, 2)),
    Dropout(0.25),
    Conv2D(64, (3, 3), activation='relu'),
    MaxPooling2D((2, 2)),
    Dropout(0.25),
    Flatten(),
    Dense(64, activation='relu'),
    Dropout(0.5),
    Dense(len(np.unique(y_train)), activation='softmax')
])

# Compile the model
model.compile(optimizer=Adam(), loss='sparse_categorical_crossentropy', metrics=['accuracy'])

# Set up callbacks
checkpoint = ModelCheckpoint("best_model.h5", save_best_only=True, verbose=1)
early_stopping = EarlyStopping(patience=5, restore_best_weights=True, verbose=1)

history = model.fit(
X_train, y_train,
validation_data=(X_val, y_val),
epochs=40,
batch_size=32,
callbacks=[checkpoint, early_stopping]
)
model.load_weights("best_model.h5")

"""test"""

# Load the best model
model = tf.keras.models.load_model("best_model.h5")

# Prepare the test data
file_names = []
X_test = []

for file in sorted(os.listdir(test_path)):
    if file.endswith(".wav"):
        file_names.append(file.split(".")[0])
        audio_data, sample_rate = librosa.load(os.path.join(test_path, file))
        spectrogram = librosa.feature.melspectrogram(y=audio_data, sr=sample_rate, n_mels=n_mels)
        spectrogram_padded = np.pad(spectrogram, ((0, 0), (0, max_time_length - spectrogram.shape[1])), mode='constant')
        X_test.append(spectrogram_padded)

X_test = np.array(X_test)[:, :, :, np.newaxis]

# Make predictions
y_pred = np.argmax(model.predict(X_test), axis=1)

# Convert the integer labels back into emotion strings
y_pred_emotions = encoder.inverse_transform(y_pred)

# Prepare the predictions for saving to a CSV file
predictions = np.column_stack((file_names, y_pred_emotions))

# Sort the predictions array by the first column (the sorted file names)
predictions = predictions[np.lexsort((predictions[:, 0],))]

# Save the predictions to a CSV file
np.savetxt("predictions.csv", predictions, fmt='%s', delimiter=",", encoding='utf-8')
with open("predictions.csv", "r+") as f:
    content = f.read()
    f.seek(0, 0)
    f.write("filename,Label\n" + content)

"""Split data

Create the CNN and train model
"""
# -*- coding: utf-8 -*-
"""cox_model_2nd_donation.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1euUmdux9D0wGzfMA3xD5O8VtXcDvlWlw
"""

import pandas as pd
import numpy as np
from collections import Counter, defaultdict
from google.colab import files
import matplotlib.pyplot as plt
import re
from lifelines import CoxPHFitter
from sklearn.model_selection import train_test_split

from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split
from lifelines import CoxPHFitter
from lifelines.utils import concordance_index
import matplotlib.pyplot as plt
from matplotlib.lines import Line2D

import warnings

# Filter out warnings
warnings.filterwarnings('ignore')

file_path = 'merged_data_v9.csv'
data = pd.read_csv(file_path)

data.columns

# Due to collinearity issues, remove a marketing column if the responses are significantly skewed to one category.
threshold = 100

# Media Type
for col in data.columns:
    if col.startswith('media_type') and any(data[col].value_counts() < threshold):
        print(f"Removing column '{col}' due to less than 100 responses in at least one category.")
        data = data.drop(col, axis=1)

# MOS
for col in data.columns:
    if col.startswith('mos') and any(data[col].value_counts() < threshold):
        print(f"Removing column '{col}' due to less than 100 responses in at least one category.")
        data = data.drop(col, axis=1)

# Sales Channel
for col in data.columns:
    if col.startswith('sales_channel') and any(data[col].value_counts() < threshold):
        print(f"Removing column '{col}' due to less than 100 responses in at least one category.")
        data = data.drop(col, axis=1)

# Calculate time between first and second donations
data['time12'] = (pd.to_datetime(data['second_donation_date']) - pd.to_datetime(data['first_donation_date'])).dt.days

data['event12'] = 0
# Set event to 1 if second donation amount is present, otherwise 0
data.loc[data['second_donation_amount'] != 0, 'event12'] = 1

# For customers with no second donation, fill `time` with the max observed time (or end of observation period)
max_time = data['time12'].max()
data['time12'].fillna(max_time, inplace=True)

data.columns

# Excluded irrelevant columns from data, including
# 'first_performance_date', 'first_donation_date',
# 'first_donation_amount', 'second_donation_date',
# 'second_donation_amount', 'third_donation_date',
#  'third_donation_amount', 'survival_time', 'early_donate'

model_data = data[['time12', 'event12', 'visit_count', 'annual_visit_freq', 'gender', 'age',
       'education', 'hhi', 'children', 'nps', 'overall_experience_score',
       'region',
       'single_viewer', 'avg diff (minutes)',

        'media_type_Default Media',
        'media_type_No Media',
        'media_type_Subscriber Renewal',
        'mos_Internet',
        'mos_Single Tickets',
       'mos_Subscription',
        'mos_TNEW Web',
        'sales_channel_Default Channel',
       'sales_channel_Phone',
      'sales_channel_Web '  ]]

df = model_data
duration_col = 'time12'
event_col = 'event12'

cox_model = CoxPHFitter()

# Fit the model
cox_model.fit(df, duration_col=duration_col, event_col=event_col)

# Display the coefficients
print("Cox Regression Coefficients:")
print(cox_model.print_summary())

# Retrieve feature importance (absolute value of coefficients as a proxy)
feature_importance = cox_model.params_.abs().sort_values(ascending=False)
print("\nFeature Importance (Absolute Coefficients):")
print(feature_importance)

coef_exp = np.exp(cox_model.params_)

# Define thresholds for feature removal
lower_threshold1 = 0.95
upper_threshold1 = 1.05
lower_threshold2 = 0.7
upper_threshold2 = 1.3

# Identify features to remove
features_to_remove = []
for feature, exp_coef in coef_exp.items():
    if (exp_coef >= lower_threshold1 and exp_coef <= upper_threshold1) or (exp_coef <= lower_threshold2 and exp_coef >= upper_threshold2):
        features_to_remove.append(feature)

print("Features removed:")
print(features_to_remove)

df = df.drop(columns=features_to_remove)

cox_model = CoxPHFitter()

# Fit the model
cox_model.fit(df, duration_col=duration_col, event_col=event_col)

# Display the coefficients
print("Cox Regression Coefficients:")
print(cox_model.print_summary())

# Define train-test split
train_df = df.sample(frac=0.8, random_state=42)  # 80% for training
test_df = df.drop(train_df.index)  # Remaining 20% for testing

# Fit the Cox model on the training dataset
cox_model = CoxPHFitter()
cox_model.fit(train_df, duration_col=duration_col, event_col=event_col)
print(cox_model.print_summary())

# Calculate training error
train_cindex = concordance_index(
    train_df[duration_col],
    -cox_model.predict_partial_hazard(train_df),
    train_df[event_col]
)
training_error = train_cindex

# Calculate testing error
test_cindex = concordance_index(
    test_df[duration_col],
    -cox_model.predict_partial_hazard(test_df),
    test_df[event_col]
)
test_error =  test_cindex

print("Training Error:", training_error)
print("Testing Error:", test_error)

# Standardize the numerical features
numerical_cols = df.columns.difference([duration_col, event_col])
scaler = StandardScaler()
df[numerical_cols] = scaler.fit_transform(df[numerical_cols])

# Initialize variables for tracking
remaining_features = list(numerical_cols)
train_cindex_history = []
val_cindex_history = []
features_removed = []

# Backward feature selection
while len(remaining_features) > 7:  # Stop when 7 features remain
    feature_cindex = {}

    for feature in remaining_features:
        temp_features = [f for f in remaining_features if f != feature]
        train_subset = train_df[[duration_col, event_col] + temp_features]
        test_subset = test_df[[duration_col, event_col] + temp_features]

        try:
            cph = CoxPHFitter(penalizer=0.1)  # Apply penalizer
            cph.fit(train_subset, duration_col=duration_col, event_col=event_col)

            # Calculate training and testing C-index
            train_cindex = concordance_index(train_subset[duration_col],
                                             -cph.predict_partial_hazard(train_subset),
                                             train_subset[event_col])
            test_cindex = concordance_index(test_subset[duration_col],
                                           -cph.predict_partial_hazard(test_subset),
                                           test_subset[event_col])

            feature_cindex[feature] = (train_cindex, test_cindex)
        except Exception as e:
            print(f"Error removing feature {feature}: {e}")

    # Find the feature whose removal has the smallest negative impact on test C-index
    best_feature_to_remove = max(feature_cindex, key=lambda f: feature_cindex[f][1])
    best_train_cindex, best_val_cindex = feature_cindex[best_feature_to_remove]

    # Track C-index and removed features
    train_cindex_history.append(best_train_cindex)
    val_cindex_history.append(best_val_cindex)
    features_removed.append(best_feature_to_remove)

    # Remove the feature
    remaining_features.remove(best_feature_to_remove)
    print(f"Removed feature '{best_feature_to_remove}', training C-index: {best_train_cindex:.4f}, testing C-index: {best_val_cindex:.4f}")

# Plot the C-index history
plt.figure(figsize=(10, 6))
plt.plot(range(len(train_cindex_history)), train_cindex_history, label="Training C-index", marker="o", color="darkred")
plt.plot(range(len(val_cindex_history)), val_cindex_history, label="Testing C-index", marker="o", color="lightcoral")

# Add a dotted line at chosen iteration
optimal_iteration = 5
plt.axvline(x=optimal_iteration, color='brown', linestyle=':')

# Create a custom legend entry for the dotted line
custom_line = Line2D([0], [0], color='brown', linestyle=':', label="Optimal Iteration")

# Add the custom legend
handles, labels = plt.gca().get_legend_handles_labels()
handles.append(custom_line)
labels.append("Optimal Iteration")

plt.xlabel("Features Removed", fontsize=18)
plt.ylabel("C-index", fontsize=18)
plt.title("Training and Testing C-index Over Feature Removal", fontsize=20)
plt.legend(handles=handles, labels=labels, fontsize=14)
plt.grid(True)
plt.show()

# Final selected features
print("Final Selected Features:", remaining_features)

# Restore features removed after the optimal iteration
restored_features = features_removed[optimal_iteration:]  # Features removed after optimal iteration
remaining_features.extend(restored_features)  # Add them back to the remaining features

# Ensure the feature list is unique and sorted (if needed)
remaining_features = sorted(set(remaining_features))

print("Features restored after optimal iteration:", restored_features)
print("Final Selected Features after restoration:", remaining_features)

"""# Ideal Customer Profile"""

def create_fastest_donation_customer(coxph_model, optimal_features):
    """
    Create an ideal customer with feature values that maximize the hazard ratio
    (minimize survival time) and plot their predicted survival curve.

    Parameters:
    - coxph_model: Trained CoxPHFitter model.
    - optimal_features: List of selected features used in the Cox model.

    Returns:
    - ideal_customer: Dict containing the feature values for the ideal customer.
    - survival_function: Pandas DataFrame of the predicted survival function.
    """

    # Get the coefficients of the trained Cox model
    coefs = coxph_model.params_

    # Create an ideal customer with feature values that maximize hazard
    ideal_customer = {}
    for feature in optimal_features:
        if feature in coefs.index:
            # Positive coefficient: Set to high value (maximize hazard)
            # Negative coefficient: Set to low value (minimize hazard)
            ideal_customer[feature] = 1 if coefs[feature] > 0 else 0
        else:
            # Handle features that were not included in the model (set to 0)
            ideal_customer[feature] = 0

    # Convert to a DataFrame for prediction
    ideal_customer_df = pd.DataFrame([ideal_customer])

    # Predict survival function for the ideal customer
    survival_function = coxph_model.predict_survival_function(ideal_customer_df)

    # Convert time index to years
    survival_function.index = survival_function.index / 365  # Assuming time is in days

    # Plot the survival curve
    plt.figure(figsize=(12, 10))
    plt.plot(survival_function.index, survival_function.values[:, 0], label='Ideal Customer', color='darkred')
    # Make axes bolder
    ax = plt.gca()  # Get current axis
    ax.spines['top'].set_linewidth(2)
    ax.spines['right'].set_linewidth(2)
    ax.spines['left'].set_linewidth(2)
    ax.spines['bottom'].set_linewidth(2)
    ax.tick_params(axis='both', which='major', width=2, length=6, labelsize=14)  # Bold ticks

    plt.xlabel('Time (Years)', fontsize=18)  # Increased font size
    plt.ylabel('Survival Probability', fontsize=18)  # Increased font size
    plt.xticks(fontsize=14)  # Increased x-tick font size
    plt.yticks(fontsize=14)  # Increased y-tick font size
    plt.title('Predicted Survival Curve for Ideal Customer in Making a 2nd Donation', fontsize=22)
    plt.legend(fontsize=14)
    plt.grid(True)
    plt.show()

    return ideal_customer, survival_function

# Train the final Cox model with the updated features
cph = CoxPHFitter(penalizer=0.1)
cph.fit(train_df[[duration_col, event_col] + remaining_features], duration_col=duration_col, event_col=event_col)

# Create the fastest donation customer based on the final model
ideal_customer, survival_function = create_fastest_donation_customer(cph, remaining_features)

# Print the feature values for the ideal customer
print("Ideal Customer:", ideal_customer)

"""# Input Sample Customer

Input any sample of customer features to predict their survival in making a 2nd donation
"""

sample_customer = {
     'visit_count': 36,
     'annual_visit_freq': 2.6,
     'gender': 1,
     'age': 2,
     'education': 1,
     'hhi': 2,
     'children': 0,
     'nps': 2,
     'overall_experience_score': 4,
     'region':  1,
     'single_viewer': 0,
     'avg diff (minutes)': 39,
     'media_type_Default Media': 0,
     'media_type_Email': 0,
     'media_type_No Media': 0,
     'media_type_Postcard': 0,
     'media_type_Telemarketing': 0,
     'media_type_Web': 0,
     'media_type_Subscriber Renewal': 0,
     'mos_Exchanges': 0,
     'mos_Group Sales': 0,
     'mos_Internet': 0,
     'mos_Patron Services': 0,
     'mos_Single Tickets': 0,
     'mos_Subscription': 1,
     'mos_TNEW Web': 0,
     'sales_channel_Default Channel': 0,
     'sales_channel_Development': 1,
     'sales_channel_Email': 0,
     'sales_channel_Mail': 0,
     'sales_channel_Phone': 0,
     'sales_channel_Web ': 0
}

# Get the features used in the final Cox model
final_model_features = cph.params_.index.tolist()

# Remove features from sample_customer that are not in the final model
for feature in list(sample_customer.keys()):  # Iterate over a copy of keys to avoid errors
    if feature not in final_model_features:
        del sample_customer[feature]

# Recreate the DataFrame from the updated sample customer data
sample_customer_df = pd.DataFrame([sample_customer])

# Predict the survival function
sample_survival_predictions = cph.predict_survival_function(sample_customer_df)

# Convert time index to years (assuming 365 days per year)
sample_survival_predictions.index = sample_survival_predictions.index / 365

# Plot the survival function for the sample customer
ax = sample_survival_predictions.plot(color='darkred', legend=False)  # Disable the legend
plt.title('Predicted Survival Curve for Sample Customer in Making a 2nd Donation')
plt.xlabel('Time (years)')
plt.ylabel('Survival Probability')

# Show the plot without a legend
plt.show()